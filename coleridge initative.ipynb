{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c80defe6",
   "metadata": {},
   "source": [
    "# import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf57c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75567670",
   "metadata": {},
   "source": [
    "# clean_text function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bf8644",
   "metadata": {},
   "source": [
    "#clean_text function should be used to clean text as mentioned on the #Evaluation page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942b4e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16db76f5",
   "metadata": {},
   "source": [
    "#function to read csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "852a36f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfilepath=\"C:/Users/hello/Downloads/coleridgeinitiative-show-us-the-data/\"\n",
    "def readcsv(filename):\n",
    "    csvfile=pd.read_csv(csvfilepath + filename)\n",
    "    return csvfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13ef0d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>pub_title</th>\n",
       "      <th>dataset_title</th>\n",
       "      <th>dataset_label</th>\n",
       "      <th>cleaned_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d0fa7568-7d8e-4db9-870f-f9c6f668c17b</td>\n",
       "      <td>The Impact of Dual Enrollment on College Degre...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f26f645-3dec-485d-b68d-f013c9e05e60</td>\n",
       "      <td>Educational Attainment of High School Dropouts...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c5d5cd2c-59de-4f29-bbb1-6a88c7b52f29</td>\n",
       "      <td>Differences in Outcomes for Female and Male St...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5c9a3bc9-41ba-4574-ad71-e25c1442c8af</td>\n",
       "      <td>Stepping Stone and Option Value in a Model of ...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c754dec7-c5a3-4337-9892-c02158475064</td>\n",
       "      <td>Parental Effort, School Resources, and Student...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  \\\n",
       "0  d0fa7568-7d8e-4db9-870f-f9c6f668c17b   \n",
       "1  2f26f645-3dec-485d-b68d-f013c9e05e60   \n",
       "2  c5d5cd2c-59de-4f29-bbb1-6a88c7b52f29   \n",
       "3  5c9a3bc9-41ba-4574-ad71-e25c1442c8af   \n",
       "4  c754dec7-c5a3-4337-9892-c02158475064   \n",
       "\n",
       "                                           pub_title  \\\n",
       "0  The Impact of Dual Enrollment on College Degre...   \n",
       "1  Educational Attainment of High School Dropouts...   \n",
       "2  Differences in Outcomes for Female and Male St...   \n",
       "3  Stepping Stone and Option Value in a Model of ...   \n",
       "4  Parental Effort, School Resources, and Student...   \n",
       "\n",
       "                           dataset_title  \\\n",
       "0  National Education Longitudinal Study   \n",
       "1  National Education Longitudinal Study   \n",
       "2  National Education Longitudinal Study   \n",
       "3  National Education Longitudinal Study   \n",
       "4  National Education Longitudinal Study   \n",
       "\n",
       "                           dataset_label  \\\n",
       "0  National Education Longitudinal Study   \n",
       "1  National Education Longitudinal Study   \n",
       "2  National Education Longitudinal Study   \n",
       "3  National Education Longitudinal Study   \n",
       "4  National Education Longitudinal Study   \n",
       "\n",
       "                           cleaned_label  \n",
       "0  national education longitudinal study  \n",
       "1  national education longitudinal study  \n",
       "2  national education longitudinal study  \n",
       "3  national education longitudinal study  \n",
       "4  national education longitudinal study  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplefilename=\"sample_submission.csv\"\n",
    "trainfilename=\"train.csv\"\n",
    "testfilename=\"sample_submission.csv\"\n",
    "traincsv=readcsv(trainfilename)\n",
    "testcsv=readcsv(testfilename)\n",
    "traincsv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24f83663",
   "metadata": {},
   "outputs": [],
   "source": [
    "traincsv['clean_pub_title'] = traincsv.pub_title.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86120a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>pub_title</th>\n",
       "      <th>dataset_title</th>\n",
       "      <th>dataset_label</th>\n",
       "      <th>cleaned_label</th>\n",
       "      <th>clean_pub_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19656</th>\n",
       "      <td>b3498176-8832-4033-aea6-b5ea85ea04c4</td>\n",
       "      <td>RSNA International Trends: A Global Perspectiv...</td>\n",
       "      <td>RSNA International COVID-19 Open Radiology Dat...</td>\n",
       "      <td>RSNA International COVID Open Radiology Database</td>\n",
       "      <td>rsna international covid open radiology database</td>\n",
       "      <td>rsna international trends a global perspective...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19657</th>\n",
       "      <td>f77eb51f-c3ac-420b-9586-cb187849c321</td>\n",
       "      <td>MCCS: a novel recognition pattern-based method...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds dat...</td>\n",
       "      <td>mccs a novel recognition pattern based method ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19658</th>\n",
       "      <td>ab59bcdd-7b7c-4107-93f5-0ccaf749236c</td>\n",
       "      <td>Quantitative Structureâ€“Activity Relationship M...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds dat...</td>\n",
       "      <td>quantitative structure activity relationship m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19659</th>\n",
       "      <td>fd23e7e0-a5d2-4f98-992d-9209c85153bb</td>\n",
       "      <td>A ligand-based computational drug repurposing ...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds dat...</td>\n",
       "      <td>a ligand based computational drug repurposing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19660</th>\n",
       "      <td>fd23e7e0-a5d2-4f98-992d-9209c85153bb</td>\n",
       "      <td>A ligand-based computational drug repurposing ...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds dat...</td>\n",
       "      <td>CAS COVID-19 antiviral candidate compounds data</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds data</td>\n",
       "      <td>a ligand based computational drug repurposing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Id  \\\n",
       "19656  b3498176-8832-4033-aea6-b5ea85ea04c4   \n",
       "19657  f77eb51f-c3ac-420b-9586-cb187849c321   \n",
       "19658  ab59bcdd-7b7c-4107-93f5-0ccaf749236c   \n",
       "19659  fd23e7e0-a5d2-4f98-992d-9209c85153bb   \n",
       "19660  fd23e7e0-a5d2-4f98-992d-9209c85153bb   \n",
       "\n",
       "                                               pub_title  \\\n",
       "19656  RSNA International Trends: A Global Perspectiv...   \n",
       "19657  MCCS: a novel recognition pattern-based method...   \n",
       "19658  Quantitative Structureâ€“Activity Relationship M...   \n",
       "19659  A ligand-based computational drug repurposing ...   \n",
       "19660  A ligand-based computational drug repurposing ...   \n",
       "\n",
       "                                           dataset_title  \\\n",
       "19656  RSNA International COVID-19 Open Radiology Dat...   \n",
       "19657  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19658  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19659  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19660  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "\n",
       "                                           dataset_label  \\\n",
       "19656   RSNA International COVID Open Radiology Database   \n",
       "19657  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19658  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19659  CAS COVID-19 antiviral candidate compounds dat...   \n",
       "19660    CAS COVID-19 antiviral candidate compounds data   \n",
       "\n",
       "                                           cleaned_label  \\\n",
       "19656   rsna international covid open radiology database   \n",
       "19657  cas covid 19 antiviral candidate compounds dat...   \n",
       "19658  cas covid 19 antiviral candidate compounds dat...   \n",
       "19659  cas covid 19 antiviral candidate compounds dat...   \n",
       "19660    cas covid 19 antiviral candidate compounds data   \n",
       "\n",
       "                                         clean_pub_title  \n",
       "19656  rsna international trends a global perspective...  \n",
       "19657  mccs a novel recognition pattern based method ...  \n",
       "19658  quantitative structure activity relationship m...  \n",
       "19659  a ligand based computational drug repurposing ...  \n",
       "19660  a ligand based computational drug repurposing ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traincsv.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce0439",
   "metadata": {},
   "source": [
    "# Read json file and map it to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15fc09b",
   "metadata": {},
   "source": [
    "#path to JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "692d50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_train=\"C:/Users/hello/Downloads/coleridgeinitiative-show-us-the-data/train/\"\n",
    "path_test=\"C:/Users/hello/Downloads/coleridgeinitiative-show-us-the-data/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a723fda",
   "metadata": {},
   "source": [
    "#read train json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa7a9057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readcsvid():\n",
    "   \n",
    "    df=pd.DataFrame()\n",
    "    dfs=pd.DataFrame()\n",
    "    file_id=[]\n",
    "    cleaned_label=[]\n",
    "    uniques = traincsv['Id'].unique() \n",
    "    for id in uniques:\n",
    "       \n",
    "        filename=id +\".json\"\n",
    "        json_file=open(os.path.join(path_train,filename))\n",
    "        dfs=pd.read_json(json_file)\n",
    "        clean_label=traincsv.loc[traincsv[\"Id\"]==id,'cleaned_label'].iloc[0]\n",
    "        dfs[\"id\"]=id\n",
    "        dfs[\"cleaned_label\"]=clean_label\n",
    "        df = pd.concat([df,dfs])\n",
    "        \n",
    "    df.to_csv(\"C:/Users/hello/Downloads/coleridgeinitiative-show-us-the-data/df_train.csv\",index=False)\n",
    "        \n",
    "    \n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f80ecff",
   "metadata": {},
   "source": [
    "# map to read test csv file to map json test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c6433423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readtestcsvid():\n",
    "    count=0\n",
    "    df=pd.DataFrame()\n",
    "    dfs=pd.DataFrame()\n",
    "    file_id=[]\n",
    "    cleaned_label=[]\n",
    "    json_files = [pos_json for pos_json in os.listdir(path_test) if pos_json.endswith('.json')]\n",
    "    for f in json_files:\n",
    "        with open(os.path.join(path_test,f)) as json_file:\n",
    "                          \n",
    "            dfs=pd.read_json(json_file)\n",
    "            \n",
    "            dfs[\"id\"]=f\n",
    "            \n",
    "            df = pd.concat([df,dfs])\n",
    "                \n",
    "            print(\"id:\", f)\n",
    "            \n",
    "    df.to_csv(\"C:/Users/hello/Downloads/coleridgeinitiative-show-us-the-data/df_test.csv\",index=False)\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d214b461",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "readcsvid() #read function to map json train file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1dea1073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 2100032a-7c33-4bff-97ef-690822c43466.json\n",
      "id: 2f392438-e215-4169-bebf-21ac4ff253e1.json\n",
      "id: 3f316b38-1a24-45a9-8d8c-4e05a42257c6.json\n",
      "id: 8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60.json\n"
     ]
    }
   ],
   "source": [
    "readtestcsvid()\n",
    "testjson=readcsv(\"df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3771ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainjson=readcsv(\"df_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "60565443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(258714, 4)\n",
      "(118, 3)\n"
     ]
    }
   ],
   "source": [
    "print(trainjson.shape)\n",
    "print(testjson.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b22aabf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section_title</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>cleaned_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258709</th>\n",
       "      <td>Retrieval of GLUT-1 data</td>\n",
       "      <td>By mapping GLUT-1 retrieved from the Open Targ...</td>\n",
       "      <td>fd23e7e0-a5d2-4f98-992d-9209c85153bb</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258710</th>\n",
       "      <td>GLUT-1 case: substructure searches in DrugBank</td>\n",
       "      <td>Hierarchical clustering of available Murcko sc...</td>\n",
       "      <td>fd23e7e0-a5d2-4f98-992d-9209c85153bb</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258711</th>\n",
       "      <td>Table 2 (continued)</td>\n",
       "      <td>The structural fragment, SMARTS string, the nu...</td>\n",
       "      <td>fd23e7e0-a5d2-4f98-992d-9209c85153bb</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258712</th>\n",
       "      <td>Experiences when using the workflow in the cla...</td>\n",
       "      <td>The workflow described herein has been used in...</td>\n",
       "      <td>fd23e7e0-a5d2-4f98-992d-9209c85153bb</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258713</th>\n",
       "      <td>Summary and conclusions</td>\n",
       "      <td>In this educational paper, we are describing a...</td>\n",
       "      <td>fd23e7e0-a5d2-4f98-992d-9209c85153bb</td>\n",
       "      <td>cas covid 19 antiviral candidate compounds dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            section_title  \\\n",
       "258709                           Retrieval of GLUT-1 data   \n",
       "258710     GLUT-1 case: substructure searches in DrugBank   \n",
       "258711                                Table 2 (continued)   \n",
       "258712  Experiences when using the workflow in the cla...   \n",
       "258713                            Summary and conclusions   \n",
       "\n",
       "                                                     text  \\\n",
       "258709  By mapping GLUT-1 retrieved from the Open Targ...   \n",
       "258710  Hierarchical clustering of available Murcko sc...   \n",
       "258711  The structural fragment, SMARTS string, the nu...   \n",
       "258712  The workflow described herein has been used in...   \n",
       "258713  In this educational paper, we are describing a...   \n",
       "\n",
       "                                          id  \\\n",
       "258709  fd23e7e0-a5d2-4f98-992d-9209c85153bb   \n",
       "258710  fd23e7e0-a5d2-4f98-992d-9209c85153bb   \n",
       "258711  fd23e7e0-a5d2-4f98-992d-9209c85153bb   \n",
       "258712  fd23e7e0-a5d2-4f98-992d-9209c85153bb   \n",
       "258713  fd23e7e0-a5d2-4f98-992d-9209c85153bb   \n",
       "\n",
       "                                            cleaned_label  \n",
       "258709  cas covid 19 antiviral candidate compounds dat...  \n",
       "258710  cas covid 19 antiviral candidate compounds dat...  \n",
       "258711  cas covid 19 antiviral candidate compounds dat...  \n",
       "258712  cas covid 19 antiviral candidate compounds dat...  \n",
       "258713  cas covid 19 antiviral candidate compounds dat...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainjson.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5642b",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "30561a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section_title</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstract</td>\n",
       "      <td>Cognitive deficits and reduced educational ach...</td>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Introduction</td>\n",
       "      <td>A general cognitive ability factor (also terme...</td>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Methods and Materials</td>\n",
       "      <td>COGENT is an international GWAS collaboration ...</td>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011) Plink was used to analyze datasets compr...</td>\n",
       "      <td>, and GCTA used to analyze five datasets in wh...</td>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Results</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       section_title  \\\n",
       "0                                           Abstract   \n",
       "1                                       Introduction   \n",
       "2                              Methods and Materials   \n",
       "3  2011) Plink was used to analyze datasets compr...   \n",
       "4                                            Results   \n",
       "\n",
       "                                                text  \\\n",
       "0  Cognitive deficits and reduced educational ach...   \n",
       "1  A general cognitive ability factor (also terme...   \n",
       "2  COGENT is an international GWAS collaboration ...   \n",
       "3  , and GCTA used to analyze five datasets in wh...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                          id  \n",
       "0  2100032a-7c33-4bff-97ef-690822c43466.json  \n",
       "1  2100032a-7c33-4bff-97ef-690822c43466.json  \n",
       "2  2100032a-7c33-4bff-97ef-690822c43466.json  \n",
       "3  2100032a-7c33-4bff-97ef-690822c43466.json  \n",
       "4  2100032a-7c33-4bff-97ef-690822c43466.json  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testjson.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f723f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6369dc7",
   "metadata": {},
   "source": [
    "\n",
    "# Using LSH \n",
    "This class of algorithms combines aspects of feature transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d3d50",
   "metadata": {},
   "source": [
    "# Efficiencies can be achieved by actually using an LSH Forest algorithm for efficient searching.\n",
    "\n",
    "the following steps for performing LSH:\n",
    "\n",
    "1.Create shingles from your available data set (e.g. unigrams, bigrams, ratings, etc.)\n",
    "\n",
    "2.Build an mÃ—n shingle matrix where every shingle that appears in a set is marked with a 1 otherwise 0.\n",
    "\n",
    "3.Permute the rows of the shingle matrix from step 2 and build a new pÃ—n signature matrix where the number of the row of the first shingle to appear for a set is recorded for the permutation of the signature matrix.\n",
    "\n",
    "4..Repeat permuting the rows of the input matrix times and complete filling in the pÃ—n signature matrix.\n",
    "\n",
    "5.Choose a band size b for the number of rows you will compare between sets in the LSH matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15ec3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7fd5407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHash, MinHashLSHForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0f7715",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c64efd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess will split a string of text into individual tokens/shingles based on whitespace.\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    tokens = text.lower()\n",
    "    tokens = tokens.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3261e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=[]\n",
    "\n",
    "label=trainjson['cleaned_label'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa037b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "086e2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "shingles=[]\n",
    "\n",
    "\n",
    "for t in label:\n",
    "    shingles.append(preprocess(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fd48c2",
   "metadata": {},
   "source": [
    "# Choose your parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77f6b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Permutations\n",
    "permutations = 128\n",
    "\n",
    "#Number of Recommendations to return\n",
    "num_recommendations = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bffa36e",
   "metadata": {},
   "source": [
    "# Create Minhash Forest for Queries\n",
    "In order to create the Minhash Forest, we will execute the following steps:\n",
    "\n",
    "1. Pass in a dataframe with every string you want to query.\n",
    "\n",
    "2. Preprocess a string of text using our preprocessing step above.\n",
    "\n",
    "3. Set the number of permutations in your MinHash.\n",
    "\n",
    "4. MinHash the string on all of your shingles in the string.\n",
    "5. Store the MinHash of the string.\n",
    "6. Repeat 2-5 for all strings in your dataframe.\n",
    "7. Build a forest of all the MinHashed strings.\n",
    "I8. ndex your forest to make it searchable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6ecd2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forest(data, perms):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    minhash = []\n",
    "    \n",
    "    for text in data['text']:\n",
    "        tokens = preprocess(str(text))\n",
    "        m = MinHash(num_perm=perms)\n",
    "        for s in tokens:\n",
    "            m.update(s.encode('utf8'))\n",
    "        minhash.append(m)\n",
    "        \n",
    "    forest = MinHashLSHForest(num_perm=perms)\n",
    "    \n",
    "    for i,m in enumerate(minhash):\n",
    "        forest.add(i,m)\n",
    "        \n",
    "    forest.index()\n",
    "    \n",
    "    print('It took %s seconds to build forest.' %(time.time()-start_time))\n",
    "    \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c613f2",
   "metadata": {},
   "source": [
    "# Evaluate Queries\n",
    "In order to query the forest that was built, we will follow the steps below:\n",
    "\n",
    "Preprocess your text into shingles.\n",
    "Set the same number of permutations for your MinHash as was used to build the forest.\n",
    "Create your MinHash on the text using all your shingles.\n",
    "Query the forest with your MinHash and return the number of requested recommendations.\n",
    "Provide the titles of each conference paper recommended.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5f0899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, database, perms, num_results, forest):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    tokens = preprocess(text)\n",
    "    m = MinHash(num_perm=perms)\n",
    "    for s in tokens:\n",
    "        m.update(s.encode('utf8'))\n",
    "        \n",
    "    idx_array = np.array(forest.query(m, num_results))\n",
    "    if len(idx_array) == 0:\n",
    "        return None # if your query is empty, return none\n",
    "    \n",
    "    result = database.iloc[idx_array]['title']\n",
    "    \n",
    "    print('It took %s seconds to query forest.' %(time.time()-start_time))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a76089",
   "metadata": {},
   "source": [
    "# Testing Our Recommendation Engine on json publication\n",
    "We will start by loading the CSV containing all the publication \n",
    "\n",
    "Finally, we can query any string of text such as a title or general topic to return a list of recommendations.  Naturally, we get the exact prediction\n",
    "as one of our recommendations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c19b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forest = get_forest(trainjson, permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c9f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_recommendations = 5\n",
    "result=[]\n",
    "for t in label:\n",
    "    result = predict(t, testjson, permutations, num_recommendations, forest)\n",
    "print('\\n Top Recommendation(s) is(are) \\n', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d265ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b281644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
