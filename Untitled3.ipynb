{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dba764c",
   "metadata": {},
   "source": [
    "# # coding: utf-8\n",
    "\n",
    "# # Locality Sensitive Hashing\n",
    "\n",
    "# Locality Sensitive Hashing (LSH) provides for a fast, efficient approximate nearest neighbor search. The algorithm scales well with respect to the number of data points as well as dimensions.\n",
    "# \n",
    "# In this assignment, you will\n",
    "# * Implement the LSH algorithm for approximate nearest neighbor search\n",
    "# * Examine the accuracy for different documents by comparing against brute force search, and also contrast runtimes\n",
    "# * Explore the role of the algorithmâ€™s tuning parameters in the accuracy of the method\n",
    "\n",
    "# **Note to Amazon EC2 users**: To conserve memory, make sure to stop all the other notebooks before running this notebook.\n",
    "\n",
    "# ## Import necessary packages\n",
    "\n",
    "# The following code block will check if you have the correct version of GraphLab Create. Any version later than 1.8.5 will do. To upgrade, read [this page](https://turi.com/download/upgrade-graphlab-create.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfbd2387",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np                                             # dense matrices\n",
    "import pandas as pd                                            # see below for install instruction\n",
    "import json\n",
    "from scipy.sparse import csr_matrix                            # sparse matrices\n",
    "from sklearn.metrics.pairwise import pairwise_distances        # pairwise distances\n",
    "from copy import copy                                          # deep copies\n",
    "import matplotlib.pyplot as plt                                # plotting\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "\n",
    "'''compute norm of a sparse vector\n",
    "   Thanks to: Jaiyam Sharma'''\n",
    "def norm(x):\n",
    "    sum_sq=x.dot(x.T)\n",
    "    norm=np.sqrt(sum_sq)\n",
    "    return(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e827dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Load in the Wikipedia dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce6995de",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = pd.read_csv('people_wiki.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb8e3e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Digby_Morrell&gt;</td>\n",
       "      <td>Digby Morrell</td>\n",
       "      <td>digby morrell born 10 october 1979 is a former...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Alfred_J._Lewy&gt;</td>\n",
       "      <td>Alfred J. Lewy</td>\n",
       "      <td>alfred j lewy aka sandy lewy graduated from un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            URI            name  \\\n",
       "0   <http://dbpedia.org/resource/Digby_Morrell>   Digby Morrell   \n",
       "1  <http://dbpedia.org/resource/Alfred_J._Lewy>  Alfred J. Lewy   \n",
       "\n",
       "                                                text  \n",
       "0  digby morrell born 10 october 1979 is a former...  \n",
       "1  alfred j lewy aka sandy lewy graduated from un...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30227595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42786, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02b00ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    data = loader['data']\n",
    "    indices = loader['indices']\n",
    "    indptr = loader['indptr']\n",
    "    shape = loader['shape']\n",
    "    \n",
    "    return csr_matrix( (data, indices, indptr), shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "213055e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_sparse_csr('people_wiki_tf_idf.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c128adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('people_wiki_map_index_to_word.json') as people_wiki_map_index_to_word:    \n",
    "    map_index_to_word = json.load(people_wiki_map_index_to_word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d05bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547979\n",
      "(59071, 547979)\n"
     ]
    }
   ],
   "source": [
    "print (len(map_index_to_word))\n",
    "print (corpus.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb1dde3",
   "metadata": {},
   "source": [
    "# For the remainder of the assignment, we will use sparse matrices. Sparse matrices are [matrices](https://en.wikipedia.org/wiki/Matrix_(mathematics%29 ) that have a small number of nonzero entries. A good data structure for sparse matrices would only store the nonzero entries to save space and speed up computation. SciPy provides a highly-optimized library for sparse matrices. Many matrix operations available for NumPy arrays are also available for SciPy sparse matrices.\n",
    "# \n",
    "# We first convert the TF-IDF column (in dictionary format) into the SciPy sparse matrix format.\n",
    "\n",
    "\n",
    "# The conversion should take a few minutes to complete.\n",
    "\n",
    "# **Checkpoint**: The following code block should return 'Check passed correctly', indicating that your matrix contains TF-IDF values for 59071 documents and 547979 unique words.  Otherwise, it will return Error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1735faa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check passed correctly!\n"
     ]
    }
   ],
   "source": [
    "assert corpus.shape == (59071, 547979)\n",
    "print ('Check passed correctly!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67146da5",
   "metadata": {},
   "source": [
    "# ## Train an LSH model\n",
    "\n",
    "# LSH performs an efficient neighbor search by randomly partitioning all reference data points into different bins. Today we will build a popular variant of LSH known as random binary projection, which approximates cosine distance. There are other variants we could use for other choices of distance metrics.\n",
    "# \n",
    "# The first step is to generate a collection of random vectors from the standard Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4397a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_vectors(num_vector, dim):\n",
    "    return np.random.randn(dim, num_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ae5e90",
   "metadata": {},
   "source": [
    "# To visualize these Gaussian random vectors, let's look at an example in low-dimensions.  Below, we generate 3 random vectors each of dimension 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b2d08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.76405235  0.40015721  0.97873798]\n",
      " [ 2.2408932   1.86755799 -0.97727788]\n",
      " [ 0.95008842 -0.15135721 -0.10321885]\n",
      " [ 0.4105985   0.14404357  1.45427351]\n",
      " [ 0.76103773  0.12167502  0.44386323]]\n"
     ]
    }
   ],
   "source": [
    "# Generate 3 random vectors of dimension 5, arranged into a single 5 x 3 matrix.\n",
    "np.random.seed(0) # set seed=0 for consistent results\n",
    "print (generate_random_vectors(num_vector=3, dim=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "effbb25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(547979, 16)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random_vectors = generate_random_vectors(num_vector=16, dim=547979)\n",
    "print (random_vectors.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a2528",
   "metadata": {},
   "source": [
    "# Next, we partition data points into bins. Instead of using explicit loops, we'd like to utilize matrix operations for greater efficiency. Let's walk through the construction step by step.\n",
    "# \n",
    "# We'd like to decide which bin document 0 should go. Since 16 random vectors were generated in the previous cell, we have 16 bits to represent the bin index. The first bit is given by the sign of the dot product between the first random vector and the document's TF-IDF vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a36f53ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "doc = corpus[0, :] # vector of tf-idf values for document 0\n",
    "print (doc.dot(random_vectors[:, 0]) >= 0) # True if positive sign; False if negative sign\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c87f18",
   "metadata": {},
   "source": [
    "# Similarly, the second bit is computed as the sign of the dot product between the second random vector and the document vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ee6eaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "print (doc.dot(random_vectors[:, 1]) >= 0) # True if positive sign; False if negative sign\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c794ce4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True False False False  True  True False  True  True  True False\n",
      "  False  True False  True]]\n",
      "[[1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# We can compute all of the bin index bits at once as follows. Note the absence of the explicit `for` loop over the 16 vectors. Matrix operations let us batch dot-product computation in a highly efficent manner, unlike the `for` loop construction. Given the relative inefficiency of loops in Python, the advantage of matrix operations is even greater.\n",
    "\n",
    "\n",
    "\n",
    "print (doc.dot(random_vectors) >= 0) # should return an array of 16 True/False bits\n",
    "print (np.array(doc.dot(random_vectors) >= 0, dtype=int)) # display index bits in 0/1's\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9aada5",
   "metadata": {},
   "source": [
    "# All documents that obtain exactly this vector will be assigned to the same bin. We'd like to repeat the identical operation on all documents in the Wikipedia dataset and compute the corresponding bin indices. Again, we use matrix operations  so that no explicit loop is needed.\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "print corpus[0:2].dot(random_vectors) >= 0 # compute bit indices of first two documents\n",
    "print corpus.dot(random_vectors) >= 0 # compute bit indices of ALL documents\n",
    "\n",
    "\n",
    "# We're almost done! To make it convenient to refer to individual bins, we convert each binary bin index into a single integer: \n",
    "# ```\n",
    "# Bin index                      integer\n",
    "# [0,0,0,0,0,0,0,0,0,0,0,0]   => 0\n",
    "# [0,0,0,0,0,0,0,0,0,0,0,1]   => 1\n",
    "# [0,0,0,0,0,0,0,0,0,0,1,0]   => 2\n",
    "# [0,0,0,0,0,0,0,0,0,0,1,1]   => 3\n",
    "# ...\n",
    "# [1,1,1,1,1,1,1,1,1,1,0,0]   => 65532\n",
    "# [1,1,1,1,1,1,1,1,1,1,0,1]   => 65533\n",
    "# [1,1,1,1,1,1,1,1,1,1,1,0]   => 65534\n",
    "# [1,1,1,1,1,1,1,1,1,1,1,1]   => 65535 (= 2^16-1)\n",
    "# ```\n",
    "# By the [rules of binary number representation](https://en.wikipedia.org/wiki/Binary_number#Decimal), we just need to compute the dot product between the document vector and the vector consisting of powers of 2:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3adb85b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True False False False  True  True False  True  True  True False\n",
      "  False  True False  True]]\n",
      "[32768 16384  8192  4096  2048  1024   512   256   128    64    32    16\n",
      "     8     4     2     1]\n",
      "[50917]\n"
     ]
    }
   ],
   "source": [
    "doc = corpus[0, :]  # first document\n",
    "index_bits = (doc.dot(random_vectors) >= 0)\n",
    "powers_of_two = (1 << np.arange(15, -1, -1))\n",
    "print (index_bits)\n",
    "print (powers_of_two)           # [32768, 16384, 8192, 4096, 2048, 1024, 512, 256, 128, 64, 32, 16, 8, 4, 2, 1]\n",
    "print (index_bits.dot(powers_of_two))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120bc7bf",
   "metadata": {},
   "source": [
    "# Since it's the dot product again, we batch it with a matrix operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34ad3ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50917 36265 19365 ... 52983 27589 41449]\n",
      "59071\n"
     ]
    }
   ],
   "source": [
    "index_bits = corpus.dot(random_vectors) >= 0\n",
    "print (index_bits.dot(powers_of_two))\n",
    "print (len(index_bits.dot(powers_of_two)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "221cd336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This array gives us the integer index of the bins for all documents.\n",
    "# \n",
    "# Now we are ready to complete the following function. Given the integer bin indices for the documents, you should compile a list of document IDs that belong to each bin. Since a list is to be maintained for each unique bin index, a dictionary of lists is used.\n",
    "# \n",
    "# 1. Compute the integer bin indices. This step is already completed.\n",
    "# 2. For each document in the dataset, do the following:\n",
    "#    * Get the integer bin index for the document.\n",
    "#    * Fetch the list of document ids associated with the bin; if no list yet exists for this bin, assign the bin an empty list.\n",
    "#    * Add the document id to the end of the list.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "767ad7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lsh(data, num_vector=16, seed=None):\n",
    "    \n",
    "    dim = data.shape[1]\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    random_vectors = generate_random_vectors(num_vector, dim)\n",
    "  \n",
    "    powers_of_two = 1 << np.arange(num_vector-1, -1, -1)\n",
    "  \n",
    "    table = {}\n",
    "    \n",
    "    # Partition data points into bins\n",
    "    bin_index_bits = (data.dot(random_vectors) >= 0)\n",
    "  \n",
    "    # Encode bin index bits into integers\n",
    "    bin_indices = bin_index_bits.dot(powers_of_two)\n",
    "    \n",
    "    # Update `table` so that `table[i]` is the list of document ids with bin index equal to i.\n",
    "    for data_index, bin_index in enumerate(bin_indices):\n",
    "        if bin_index not in table:\n",
    "            # If no list yet exists for this bin, assign the bin an empty list.\n",
    "            table[bin_index] = [] # YOUR CODE HERE\n",
    "        # Fetch the list of document ids associated with the bin and add the document id to the end.\n",
    "        # YOUR CODE HERE\n",
    "        table[bin_index].append(data_index)\n",
    "\n",
    "    model = {'data': data,\n",
    "             'bin_index_bits': bin_index_bits,\n",
    "             'bin_indices': bin_indices,\n",
    "             'table': table,\n",
    "             'random_vectors': random_vectors,\n",
    "             'num_vector': num_vector}\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7751879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "model = train_lsh(corpus, num_vector=16, seed=143)\n",
    "table = model['table']\n",
    "if   0 in table and table[0]   == [39583] and    143 in table and table[143] == [19693, 28277, 29776, 30399]:\n",
    "    print ('Passed!')\n",
    "else:\n",
    "    print ('Check your code.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22a8db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Note.** We will be using the model trained here in the following sections, unless otherwise indicated.\n",
    "\n",
    "# ## Inspect bins\n",
    "\n",
    "# Let us look at some documents and see which bins they fall into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0043892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              URI          name  \\\n",
      "35811  <http://dbpedia.org/resource/Barack_Obama>  Barack Obama   \n",
      "\n",
      "                                                    text  \n",
      "35811  barack hussein obama ii brk husen bm born augu...  \n"
     ]
    }
   ],
   "source": [
    "print (wiki[wiki['name'] == 'Barack Obama'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e6a3df",
   "metadata": {},
   "source": [
    "# **Quiz Question**. What is the document `id` of Barack Obama's article?\n",
    "# \n",
    "# **Quiz Question**. Which bin contains Barack Obama's article? Enter its integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83ab7a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print (np.array(model['bin_index_bits'][22745], dtype=int)) # list of 0/1's\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48285f29",
   "metadata": {},
   "source": [
    "# Recall from the previous assignment that Joe Biden was a close neighbor of Barack Obama.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c9202d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           URI       name  \\\n",
      "24478  <http://dbpedia.org/resource/Joe_Biden>  Joe Biden   \n",
      "\n",
      "                                                    text  \n",
      "24478  joseph robinette joe biden jr dosf rbnt badn b...  \n"
     ]
    }
   ],
   "source": [
    "print (wiki[wiki['name'] == 'Joe Biden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96ab6f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print (np.array(model['bin_index_bits'][24478], dtype=int)) # list of 0/1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f211582c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-a4917cd2690d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e168a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39dba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wiki[wiki['name']=='Wynn Normington Hugh-Jones']\n",
    "\n",
    "\n",
    "print (wiki[wiki['name']=='Wynn Normington Hugh-Jones'])\n",
    "\n",
    "print (np.array(model['bin_index_bits'][22745], dtype=int)) # list of 0/1's\n",
    "print (np.sum(np.array(model['bin_index_bits'][35817] == model['bin_index_bits'][22745])))\n",
    "\n",
    "\n",
    "# How about the documents in the same bin as Barack Obama? Are they necessarily more similar to Obama than Biden?  Let's look at which documents are in the same bin as the Barack Obama article.\n",
    "\n",
    "model['bin_indices'][35817]\n",
    "\n",
    "print (model['table'][model['bin_indices'][35817]])\n",
    "\n",
    "\n",
    "# There are four other documents that belong to the same bin. Which documents are they?\n",
    "\n",
    "\n",
    "\n",
    "doc_ids = list(model['table'][model['bin_indices'][35817]])\n",
    "#doc_ids.remove(35817) # display documents other than Obama\n",
    "\n",
    "#wiki.loc[doc_ids] # filter by id column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa0b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cosine_distance(x, y):\n",
    "    xy = x.dot(y.T)\n",
    "    dist = xy/(norm(x)*norm(y))\n",
    "    return 1-dist[0,0]\n",
    "\n",
    "obama_tf_idf = corpus[35817,:]\n",
    "biden_tf_idf = corpus[24478,:]\n",
    "\n",
    "print ('================= Cosine distance from Barack Obama')\n",
    "print ('Barack Obama - {0:24s}: {1:f}'.format('Joe Biden',cosine_distance(obama_tf_idf, biden_tf_idf)))\n",
    "for doc_id in doc_ids:\n",
    "    doc_tf_idf = corpus[doc_id,:]\n",
    "    print ('Barack Obama - {0:24s}: {1:f}'.format(wiki.iloc[doc_id]['name'],cosine_distance(obama_tf_idf, doc_tf_idf)))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7786146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
